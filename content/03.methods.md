## Methods

### Data Acquisition and Processing

#### Text Scraping

All scraped text and metadata were scraped using the web-crawling framework Scrapy [@https://scrapy.org/] (version 2.4.1).
Three independent scrapy web spiders were generated to process the news text, news citations, and research article metadata.
News articles were defined as all articles from 2005-2020 that were designated as "News", "News-and-Views", "News-Feature", "Career-Column", "Career-Feature", "Technology-Feature", and "Toolbox".
Using the spider “target_year_crawl.py”, the title, author, and main text were scraped from all news articles.
The main text was character normalized by mapping visually identical Unicode codepoints to a single Unicode codepoint and stripping all non-Unicode characters.
Citations within news articles were scraped using an additional spider defined in “doi_crawl.py”.
In this spider, the only citations with a Springer DOI included in either text or a hyperlink were considered.
The spider “article_author_crawl.py”, scraped all research articles that were designated as "Article" or "Letters".
Only author names, author positions, and associated affiliations are scrapped from research articles.
It should be noted that news article designations changed over time, but it is beyond the scope of this analysis to automatically identify more fine-grained article definitions.

#### Springer API

The Springer API was used to generate a comparative background set for supplemental analyses and to get author information of articles cited by news articles.
To generate the Springer background set, a random set of articles were selected.
These articles were the the first 200 English language "Journal" articles returned by the Springer API for each month, resulting in 2400 articles per year, for the years 2005-2020.
To get the author information for the cited articles, the scraped DOI was used to query the springer API.
For both API query types, the author names, positions, and affiliations for each publication were stored and are available in "all_author_country.tsv" and "all_author_fullname.tsv".
Names were processed using the R package humaniformat [@https://cran.r-project.org/web/packages/humaniformat/index.html].

### Quote Analysis

The quote extraction and attribution annotator from the coreNLP pipeline was employed to identify quotes and their associated speakers in the news article text.
Since the full name of the speaker is needed for gender and origin predictions, when possible, the coreNLP predicted speaker is replaced with a longer name with minimal edit distance that was mentioned within the same article.
A matching name is defined as a name with smallest edit distance, where character deletions have zero cost.
Deletion was assigned a zero cost because we would like exact substring matches (e.g. John and John Smith should better match than John and Johan Li).
Furthermore, this same name matching strategy was used to identify if a quoted speaker was also cited.

Gender of authors and speakers were predicted using the R package genderizeR [@https://github.com/kalimu/genderizeR], which queries the genderize.io API.
The first name is used to make the prediction with a minimum cutoff of 50% to be predicted as a male associated name.
To reduce the amount of queries made to genderize.io, a previously cached gender predictions from [CITE], was additionally used and can be found in the file "genderize.tsv".
All additional first name predictions can be found in "genderize_update.tsv".

For the quote gender analyses, the proportion of total quotes, not quoted speakers, are used to esetimate the gender gap.
This was done in order to measure speaker participation instead of only diversity of speakers.
Additionally, this implies a comparison between a quote and a publication since we directly compare the proportion of male authorship against the proportion of male quotes.
Bootstrapped estimations were done by subsampling either quotes or publications, when appropriate. 

### Name Origin Analysis

For the name origin analysis, we used the same quoted speakers and cited authors described in the previous section.
In contrast to the gender prediction, we use the full name for predict name origin.
All extracted full names were submitted to Wiki-2019LSTM [CITE] in order to predict one of ten possible name origins: African, CelticEnglish, EastAsian, European, Greek, Hispanic, Jewish, ArabTurkPers, Nordic, and SouthAsia.
The resultant assignment was set as the highest probability origin.

Similar to the gender analyses, quote proportions were again directly compared against publication rates.
For citations, the proportion is calculated over all news citations for a given year.
Bootstrapped estimations were done by subsampling either quotes or publications, when appropriate. 


### Country Mention Proportions

To estimate the prevalence of a country being talked about, all organizations, countries, states, or provinces identified by coreNLP's named entity annotater were processed.
The resultant terms were then queried using Open Street Map [CITE] in order to identify the associated country with the term.
Since the terms identified by coreNLP may be ambiguous causing Open Street Map may return incorrect locations, a country is only considered to be mentioned, when a country is associated with at least two unique terms in the article.
The proportion that a country is mentioned is calculated as the number of article mentions for a specific country, divided by the total articles for a particular year.

### Country Citation Proportions

To identify the citation rate of a particular country, we processed all affiliations of all authors for a particular articles.
Since the affiliations could be in multiple formats, we again used Open Street Map to identify the country affiliation.
If the article included multiple affiliations for a single author, all were considered.
The proportion that a country was cited was calculated as the number of citations for a country divided by either the number of Nature articles for that year or the total number of articles cited by news article for that year.


### Divergent Word Identification

After calculation of the citation and mention proportion for each country, we identified countries that were outlying in either their comparitive citation or mention rate.
This was done by subtracting the citation and mention rates, then identifying which countries were in the top or bottom 5% from each year.
We only considered countries that were only identified as either high citation (Class C) or high mention (Class M) across all years.
Countries that are in the top and bottom 5% in different years (i.e. United States and United Kingdom) were removed from consideration.
Additionally, a country was only considered if it was cited or mentioned at least five times in a given year.
Once class C/M countries were identified, we sought to analyze the word frequencies in all news articles where the class C/M country was mentioned, but not cited.
We believe this would provide insight if the two types of countries were discussed differently.
Using the R package tidytext [CITE] we extracted tokens, removed stop words, and calculated the token frequencies across all articles.
We only consider tokens in class C/M articles, if the token has been observed at least 100 times across all articles.
We then identify tokens that have the largest ratio of usage between the two classes.
Since there are differences in the number of articles per country within each class, we calculated the frequency of a token within a class as the median frequency within each countries associated articles.
The resultant token ratio is calculated as the country normalized citation frequency /  country normalized mention frequency, where the term must have been observed at least once in each class.
